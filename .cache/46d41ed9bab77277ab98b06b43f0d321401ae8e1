{"_ts": 1761542969.894614, "data": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<feed xmlns=\"http://www.w3.org/2005/Atom\">\n  <link href=\"http://arxiv.org/api/query?search_query%3DSampling%20and%20Identity-Testing%20Without%20Approximate%20Tensorization%20of%20Entropy%26id_list%3D%26start%3D0%26max_results%3D25\" rel=\"self\" type=\"application/atom+xml\"/>\n  <title type=\"html\">ArXiv Query: search_query=Sampling and Identity-Testing Without Approximate Tensorization of Entropy&amp;id_list=&amp;start=0&amp;max_results=25</title>\n  <id>http://arxiv.org/api/saDiHQ5AecWh8k1Hkhq/O9JkI9M</id>\n  <updated>2025-10-27T00:00:00-04:00</updated>\n  <opensearch:totalResults xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">2864673</opensearch:totalResults>\n  <opensearch:startIndex xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">0</opensearch:startIndex>\n  <opensearch:itemsPerPage xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">25</opensearch:itemsPerPage>\n  <entry>\n    <id>http://arxiv.org/abs/2506.23456v1</id>\n    <updated>2025-06-30T01:36:32Z</updated>\n    <published>2025-06-30T01:36:32Z</published>\n    <title>Sampling and Identity-Testing Without Approximate Tensorization of\n  Entropy</title>\n    <summary>  Certain tasks in high-dimensional statistics become easier when the\nunderlying distribution satisfies a local-to-global property called approximate\ntensorization of entropy (ATE). For example, the Glauber dynamics Markov chain\nof an ATE distribution mixes fast and can produce approximate samples in a\nsmall amount of time, since such a distribution satisfies a modified\nlog-Sobolev inequality. Moreover, identity-testing for an ATE distribution\nrequires few samples if the tester is given coordinate conditional access to\nthe unknown distribution, as shown by Blanca, Chen, \\v{S}tefankovi\\v{c}, and\nVigoda (COLT 2023).\n  A natural class of distributions that do not satisfy ATE consists of mixtures\nof (few) distributions that do satisfy ATE. We study the complexity of\nidentity-testing and sampling for these distributions. Our main results are the\nfollowing:\n  1. We show fast mixing of Glauber dynamics from a data-based initialization,\nwith optimal sample complexity, for mixtures of distributions satisfying\nmodified log-Sobolev inequalities. This extends work of Huang, Koehler, Lee,\nMohanty, Rajaraman, Vuong, and Wu (STOC 2025, COLT 2025) for mixtures of\ndistributions satisfying Poincar\\'e inequalities.\n  2. Answering an open question posed by Blanca et al., we give efficient\nidentity-testers for mixtures of ATE distributions in the\ncoordinate-conditional sampling access model. We also give some simplifications\nand improvements to the original algorithm of Blanca et al.\n</summary>\n    <author>\n      <name>William Gay</name>\n    </author>\n    <author>\n      <name>William He</name>\n    </author>\n    <author>\n      <name>Nicholas Kocurek</name>\n    </author>\n    <author>\n      <name>Ryan O'Donnell</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/2506.23456v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2506.23456v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"math.ST\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"math.ST\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"stat.ML\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"stat.TH\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2307.08212v1</id>\n    <updated>2023-07-17T03:08:17Z</updated>\n    <published>2023-07-17T03:08:17Z</published>\n    <title>Combinatorial Approach for Factorization of Variance and Entropy in Spin\n  Systems</title>\n    <summary>  We present a simple combinatorial framework for establishing approximate\ntensorization of variance and entropy in the setting of spin systems (a.k.a.\nundirected graphical models) based on balanced separators of the underlying\ngraph. Such approximate tensorization results immediately imply as corollaries\nmany important structural properties of the associated Gibbs distribution, in\nparticular rapid mixing of the Glauber dynamics for sampling. We prove\napproximate tensorization by recursively establishing block factorization of\nvariance and entropy with a small balanced separator of the graph. Our approach\ngoes beyond the classical canonical path method for variance and the recent\nspectral independence approach, and allows us to obtain new rapid mixing\nresults. As applications of our approach, we show that:\n  1. On graphs of treewidth $t$, the mixing time of the Glauber dynamics is\n$n^{O(t)}$, which recovers the recent results of Eppstein and Frishberg with\nimproved exponents and simpler proofs;\n  2. On bounded-degree planar graphs, strong spatial mixing implies\n$\\tilde{O}(n)$ mixing time of the Glauber dynamics, which gives a faster\nalgorithm than the previous deterministic counting algorithm by Yin and Zhang.\n</summary>\n    <author>\n      <name>Zongchen Chen</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/2307.08212v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2307.08212v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DM\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"math.CO\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"math.PR\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/1005.2327v1</id>\n    <updated>2010-05-13T14:21:55Z</updated>\n    <published>2010-05-13T14:21:55Z</published>\n    <title>Black hole entropy in scalar-tensor and f(R) gravity: an overview</title>\n    <summary>  A short overview of black hole entropy in alternative gravitational theories\nis presented. Motivated by the recent attempts to explain the cosmic\nacceleration without dark energy, we focus on metric and Palatini f(R) gravity\nand on scalar-tensor theories.\n</summary>\n    <author>\n      <name>Valerio Faraoni</name>\n      <arxiv:affiliation xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Bishop's University</arxiv:affiliation>\n    </author>\n    <arxiv:doi xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10.3390/e12051246</arxiv:doi>\n    <link title=\"doi\" href=\"http://dx.doi.org/10.3390/e12051246\" rel=\"related\"/>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">24 pages, latex, to appear in \"Entropy in Quantum Gravity\", special\n  issue of Entropy, R. Garattini editor.</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/1005.2327v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1005.2327v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"gr-qc\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"gr-qc\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2012.05573v2</id>\n    <updated>2022-01-05T09:26:12Z</updated>\n    <published>2020-12-10T10:42:44Z</published>\n    <title>Entropy and reversible catalysis</title>\n    <summary>  I show that non-decreasing entropy provides a necessary and sufficient\ncondition to convert the state of a physical system into a different state by a\nreversible transformation that acts on the system of interest and a further\n\"catalyst\" whose state has to remain invariant exactly in the transition. This\nstatement is proven both in the case of finite-dimensional quantum mechanics,\nwhere von~Neumann entropy is the relevant entropy, and in the case of systems\nwhose states are described by probability distributions on finite sample\nspaces, where Shannon entropy is the relevant entropy. The results give an\naffirmative resolution to the (approximate) \"catalytic entropy conjecture\"\nintroduced by Boes et al. [PRL 122, 210402 (2019)]. They provide a complete\nsingle-shot characterization without external randomness of von Neumann entropy\nand Shannon entropy. I also compare the results to the setting of\nphenomenological thermodynamics and show how they can be used to obtain a\nquantitative single-shot characterization of Gibbs states in quantum\nstatistical mechanics.\n</summary>\n    <author>\n      <name>Henrik Wilming</name>\n    </author>\n    <arxiv:doi xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10.1103/PhysRevLett.127.260402</arxiv:doi>\n    <link title=\"doi\" href=\"http://dx.doi.org/10.1103/PhysRevLett.127.260402\" rel=\"related\"/>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">5+5 pages; 3+1 figures. Comments welcome!; v2: added comparison to\n  thermodynamics and application to quantum statistical mechanics, expanded\n  appendix, minor corrections, close to published version</arxiv:comment>\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Phys. Rev. Lett. 127, 260402 (2021)</arxiv:journal_ref>\n    <link href=\"http://arxiv.org/abs/2012.05573v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2012.05573v2\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"quant-ph\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"quant-ph\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cond-mat.stat-mech\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"math-ph\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"math.MP\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"math.PR\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2206.10154v2</id>\n    <updated>2022-06-30T00:55:17Z</updated>\n    <published>2022-06-21T07:25:39Z</published>\n    <title>Rigorous biaxial limit of a molecular-theory-based two-tensor\n  hydrodynamics</title>\n    <summary>  We consider a two-tensor hydrodynamics derived from the molecular model,\nwhere high-order tensors are determined by closure approximation through the\nmaximum entropy state or the quasi-entropy. We prove the existence and\nuniqueness of local in time smooth solutions to the two-tensor system. Then, we\nrigorously justify the connection between the molecular-theory-based two-tensor\nhydrodynamics and the biaxial frame hydrodynamics. More specifically, in the\nframework of Hilbert expansion, we show the convergence of the solution to the\ntwo-tensor hydrodynamics to the solution to the frame hydrodynamics.\n</summary>\n    <author>\n      <name>Sirui Li</name>\n    </author>\n    <author>\n      <name>Jie Xu</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">41 pages</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/2206.10154v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2206.10154v2\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"math.AP\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"math.AP\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cond-mat.soft\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"physics.flu-dyn\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"35Q35, 35A01, 35C20, 76A15\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2312.07874v3</id>\n    <updated>2024-08-30T21:11:17Z</updated>\n    <published>2023-12-13T03:30:33Z</published>\n    <title>Efficient Entropy-Stable Discontinuous Spectral-Element Methods Using\n  Tensor-Product Summation-by-Parts Operators on Triangles and Tetrahedra</title>\n    <summary>  We present a new class of efficient and robust discontinuous spectral-element\nmethods of arbitrary order for nonlinear hyperbolic systems of conservation\nlaws on curved triangular and tetrahedral unstructured grids. Such\ndiscretizations employ a recently introduced family of sparse tensor-product\nsummation-by-parts (SBP) operators in collapsed coordinates within an\nentropy-stable modal formulation. The proposed algorithms exploit the structure\nof such SBP operators alongside that of the Proriol-Koornwinder-Dubiner\npolynomial basis, and a weight-adjusted approximation is used to efficiently\ninvert the local mass matrix for curvilinear elements. Using such techniques,\nthe number of required entropy-conservative two-point flux evaluations between\npairs of quadrature nodes is significantly reduced relative to existing\nentropy-stable formulations using (non-tensor-product) multidimensional SBP\noperators, particularly for high polynomial degrees, with an improvement in\ntime complexity from $\\mathcal{O}(p^{2d})$ to $\\mathcal{O}(p^{d+1})$, where $p$\nis the polynomial degree of the approximation and $d$ is the number of spatial\ndimensions. In numerical experiments involving smooth solutions to the\ncompressible Euler equations, the proposed tensor-product schemes demonstrate\nsimilar levels of accuracy for a given mesh and polynomial degree to those\nusing multidimensional SBP operators based on symmetric quadrature rules.\nFurthermore, both operator families are shown to give rise to entropy-stable\nmethods which exhibit excellent robustness for under-resolved problems. Such\nresults suggest that the algorithmic advantages resulting from the use of\ntensor-product operators are obtained without compromising accuracy or\nrobustness, enabling the efficient extension of the benefits of entropy\nstability to higher polynomial degrees than previously considered for\ntriangular and tetrahedral elements.\n</summary>\n    <author>\n      <name>Tristan Montoya</name>\n    </author>\n    <author>\n      <name>David W. Zingg</name>\n    </author>\n    <arxiv:doi xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10.1016/j.jcp.2024.113360</arxiv:doi>\n    <link title=\"doi\" href=\"http://dx.doi.org/10.1016/j.jcp.2024.113360\" rel=\"related\"/>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">38 pages, 9 figures</arxiv:comment>\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Journal of Computational Physics 516:113360, 2024</arxiv:journal_ref>\n    <link href=\"http://arxiv.org/abs/2312.07874v3\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2312.07874v3\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"math.NA\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"math.NA\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.NA\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"physics.comp-ph\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"65M12, 65M60, 65M70\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2406.11092v1</id>\n    <updated>2024-06-16T22:45:56Z</updated>\n    <published>2024-06-16T22:45:56Z</published>\n    <title>Guaranteed Sampling Flexibility for Low-tubal-rank Tensor Completion</title>\n    <summary>  While Bernoulli sampling is extensively studied in tensor completion, t-CUR\nsampling approximates low-tubal-rank tensors via lateral and horizontal\nsubtensors. However, both methods lack sufficient flexibility for diverse\npractical applications. To address this, we introduce Tensor Cross-Concentrated\nSampling (t-CCS), a novel and straightforward sampling model that advances the\nmatrix cross-concentrated sampling concept within a tensor framework. t-CCS\neffectively bridges the gap between Bernoulli and t-CUR sampling, offering\nadditional flexibility that can lead to computational savings in various\ncontexts. A key aspect of our work is the comprehensive theoretical analysis\nprovided. We establish a sufficient condition for the successful recovery of a\nlow-rank tensor from its t-CCS samples. In support of this, we also develop a\ntheoretical framework validating the feasibility of t-CUR via uniform random\nsampling and conduct a detailed theoretical sampling complexity analysis for\ntensor completion problems utilizing the general Bernoulli sampling model.\nMoreover, we introduce an efficient non-convex algorithm, the Iterative t-CUR\nTensor Completion (ITCURTC) algorithm, specifically designed to tackle the\nt-CCS-based tensor completion. We have intensively tested and validated the\neffectiveness of the t-CCS model and the ITCURTC algorithm across both\nsynthetic and real-world datasets.\n</summary>\n    <author>\n      <name>Bowen Su</name>\n    </author>\n    <author>\n      <name>Juntao You</name>\n    </author>\n    <author>\n      <name>HanQin Cai</name>\n    </author>\n    <author>\n      <name>Longxiu Huang</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/2406.11092v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2406.11092v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.NA\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"math.NA\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"stat.ML\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2305.00754v3</id>\n    <updated>2025-01-01T23:02:11Z</updated>\n    <published>2023-05-01T10:21:52Z</published>\n    <title>A note on generalized tensor CUR approximation for tensor pairs and\n  tensor triplets based on the tubal product</title>\n    <summary>  In this note, we briefly present a generalized tensor CUR (GTCUR)\napproximation for tensor pairs (X,Y) and tensor triplets (X,Y,Z) based on the\ntubal product (t-product). We use the tensor Discrete Empirical Interpolation\nMethod (TDEIM) to do these extensions. We show how the TDEIM can be utilized to\ngeneralize the classical tensor CUR (TCUR) approximation, which acts only on a\nsingle tensor, to jointly compute the TCUR of two and three tensors. This\napproach can be used to sample relevant lateral/horizontal slices of one data\ntensor relative to one or two other data tensors. For some special cases, the\nGeneralized TCUR (GTCUR) approximation is reduced to the classical TCUR for\nboth tensor pairs and tensor triplets in a similar fashion as shown for the\nmatrices.\n</summary>\n    <author>\n      <name>Salman Ahmadi-Asl</name>\n    </author>\n    <author>\n      <name>Naeim Rezaeian</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/2305.00754v3\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2305.00754v3\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"math.NA\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"math.NA\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.NA\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/1912.03435v1</id>\n    <updated>2019-12-07T04:27:35Z</updated>\n    <published>2019-12-07T04:27:35Z</published>\n    <title>Tensor Low Rank Modeling and Its Applications in Signal Processing</title>\n    <summary>  Modeling of multidimensional signal using tensor is more convincing than\nrepresenting it as a collection of matrices. The tensor based approaches can\nexplore the abundant spatial and temporal structures of the mutlidimensional\nsignal. The backbone of this modeling is the mathematical foundations of tensor\nalgebra. The linear transform based tensor algebra furnishes low complex and\nhigh performance algebraic structures suitable for the introspection of the\nmultidimensional signal. A comprehensive introduction of the linear transform\nbased tensor algebra is provided from the signal processing viewpoint. The rank\nof a multidimensional signal is a precious property which gives an insight into\nthe structural aspects of it. All natural multidimensional signals can be\napproximated to a low rank signal without losing significant information. The\nlow rank approximation is beneficial in many signal processing applications\nsuch as denoising, missing sample estimation, resolution enhancement,\nclassification, background estimation, object detection, deweathering,\nclustering and much more applications. Detailed case study of the ways and\nmeans of the low rank modeling in the above said signal processing applications\nare also presented.\n</summary>\n    <author>\n      <name>Baburaj Madathil</name>\n    </author>\n    <author>\n      <name>Sameera V Mohd Sagheer</name>\n    </author>\n    <author>\n      <name>Abdu Rahiman V</name>\n    </author>\n    <author>\n      <name>Anju Jose Tom</name>\n    </author>\n    <author>\n      <name>Baiju P S</name>\n    </author>\n    <author>\n      <name>Jobin Francis</name>\n    </author>\n    <author>\n      <name>Sudhish N. George</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/1912.03435v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1912.03435v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"eess.SP\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"eess.SP\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/1502.05023v2</id>\n    <updated>2015-02-19T21:05:53Z</updated>\n    <published>2015-02-17T20:23:13Z</published>\n    <title>A New Sampling Technique for Tensors</title>\n    <summary>  In this paper we propose new techniques to sample arbitrary third-order\ntensors, with an objective of speeding up tensor algorithms that have recently\ngained popularity in machine learning. Our main contribution is a new way to\nselect, in a biased random way, only $O(n^{1.5}/\\epsilon^2)$ of the possible\n$n^3$ elements while still achieving each of the three goals: \\\\ {\\em (a)\ntensor sparsification}: for a tensor that has to be formed from arbitrary\nsamples, compute very few elements to get a good spectral approximation, and\nfor arbitrary orthogonal tensors {\\em (b) tensor completion:} recover an\nexactly low-rank tensor from a small number of samples via alternating least\nsquares, or {\\em (c) tensor factorization:} approximating factors of a low-rank\ntensor corrupted by noise. \\\\ Our sampling can be used along with existing\ntensor-based algorithms to speed them up, removing the computational bottleneck\nin these methods.\n</summary>\n    <author>\n      <name>Srinadh Bhojanapalli</name>\n    </author>\n    <author>\n      <name>Sujay Sanghavi</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">29 pages,3 figures</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/1502.05023v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1502.05023v2\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"stat.ML\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"stat.ML\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.IT\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"math.IT\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2207.09102v3</id>\n    <updated>2024-08-30T16:03:53Z</updated>\n    <published>2022-07-19T06:49:24Z</published>\n    <title>Complexity of High-Dimensional Identity Testing with Coordinate\n  Conditional Sampling</title>\n    <summary>  We study the identity testing problem for high-dimensional distributions.\nGiven as input an explicit distribution $\\mu$, an $\\varepsilon&gt;0$, and access\nto sampling oracle(s) for a hidden distribution $\\pi$, the goal in identity\ntesting is to distinguish whether the two distributions $\\mu$ and $\\pi$ are\nidentical or are at least $\\varepsilon$-far apart. When there is only access to\nfull samples from the hidden distribution $\\pi$, it is known that exponentially\nmany samples (in the dimension) may be needed for identity testing, and hence\nprevious works have studied identity testing with additional access to various\n\"conditional\" sampling oracles. We consider a significantly weaker conditional\nsampling oracle, which we call the $\\mathsf{Coordinate\\ Oracle}$, and provide a\ncomputational and statistical characterization of the identity testing problem\nin this new model.\n  We prove that if an analytic property known as approximate tensorization of\nentropy holds for an $n$-dimensional visible distribution $\\mu$, then there is\nan efficient identity testing algorithm for any hidden distribution $\\pi$ using\n$\\tilde{O}(n/\\varepsilon)$ queries to the $\\mathsf{Coordinate\\ Oracle}$.\nApproximate tensorization of entropy is a pertinent condition as recent works\nhave established it for a large class of high-dimensional distributions. We\nalso prove a computational phase transition: for a well-studied class of\n$n$-dimensional distributions, specifically sparse antiferromagnetic Ising\nmodels over $\\{+1,-1\\}^n$, we show that in the regime where approximate\ntensorization of entropy fails, there is no efficient identity testing\nalgorithm unless $\\mathsf{RP}=\\mathsf{NP}$. We complement our results with a\nmatching $\\Omega(n/\\varepsilon)$ statistical lower bound for the sample\ncomplexity of identity testing in the $\\mathsf{Coordinate\\ Oracle}$ model.\n</summary>\n    <author>\n      <name>Antonio Blanca</name>\n    </author>\n    <author>\n      <name>Zongchen Chen</name>\n    </author>\n    <author>\n      <name>Daniel \u0160tefankovi\u010d</name>\n    </author>\n    <author>\n      <name>Eric Vigoda</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/2207.09102v3\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2207.09102v3\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.DS\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"math.PR\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"math.ST\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"stat.TH\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2103.11037v2</id>\n    <updated>2021-06-25T21:29:00Z</updated>\n    <published>2021-03-19T22:00:21Z</published>\n    <title>Mode-wise Tensor Decompositions: Multi-dimensional Generalizations of\n  CUR Decompositions</title>\n    <summary>  Low rank tensor approximation is a fundamental tool in modern machine\nlearning and data science. In this paper, we study the characterization,\nperturbation analysis, and an efficient sampling strategy for two primary\ntensor CUR approximations, namely Chidori and Fiber CUR. We characterize exact\ntensor CUR decompositions for low multilinear rank tensors. We also present\ntheoretical error bounds of the tensor CUR approximations when (adversarial or\nGaussian) noise appears. Moreover, we show that low cost uniform sampling is\nsufficient for tensor CUR approximations if the tensor has an incoherent\nstructure. Empirical performance evaluations, with both synthetic and\nreal-world datasets, establish the speed advantage of the tensor CUR\napproximations over other state-of-the-art low multilinear rank tensor\napproximations.\n</summary>\n    <author>\n      <name>HanQin Cai</name>\n    </author>\n    <author>\n      <name>Keaton Hamm</name>\n    </author>\n    <author>\n      <name>Longxiu Huang</name>\n    </author>\n    <author>\n      <name>Deanna Needell</name>\n    </author>\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">The Journal of Machine Learning Research 22.185 (2021): 1-36</arxiv:journal_ref>\n    <link href=\"http://arxiv.org/abs/2103.11037v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2103.11037v2\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"math.NA\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"math.NA\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.IT\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.NA\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"eess.IV\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"math.IT\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2404.09155v2</id>\n    <updated>2025-02-19T03:11:50Z</updated>\n    <published>2024-04-14T06:10:46Z</published>\n    <title>Mitigating Heterogeneity among Factor Tensors via Lie Group Manifolds\n  for Tensor Decomposition Based Temporal Knowledge Graph Embedding</title>\n    <summary>  Recent studies have highlighted the effectiveness of tensor decomposition\nmethods in the Temporal Knowledge Graphs Embedding (TKGE) task. However, we\nfound that inherent heterogeneity among factor tensors in tensor decomposition\nsignificantly hinders the tensor fusion process and further limits the\nperformance of link prediction. To overcome this limitation, we introduce a\nnovel method that maps factor tensors onto a unified smooth Lie group manifold\nto make the distribution of factor tensors approximating homogeneous in tensor\ndecomposition. We provide the theoretical proof of our motivation that\nhomogeneous tensors are more effective than heterogeneous tensors in tensor\nfusion and approximating the target for tensor decomposition based TKGE\nmethods. The proposed method can be directly integrated into existing tensor\ndecomposition based TKGE methods without introducing extra parameters.\nExtensive experiments demonstrate the effectiveness of our method in mitigating\nthe heterogeneity and in enhancing the tensor decomposition based TKGE models.\n</summary>\n    <author>\n      <name>Jiang Li</name>\n    </author>\n    <author>\n      <name>Xiangdong Su</name>\n    </author>\n    <author>\n      <name>Guanglai Gao</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/2404.09155v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2404.09155v2\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2401.04249v1</id>\n    <updated>2024-01-08T21:47:15Z</updated>\n    <published>2024-01-08T21:47:15Z</published>\n    <title>A DEIM Tucker Tensor Cross Algorithm and its Application to Dynamical\n  Low-Rank Approximation</title>\n    <summary>  We introduce a Tucker tensor cross approximation method that constructs a\nlow-rank representation of a $d$-dimensional tensor by sparsely sampling its\nfibers. These fibers are selected using the discrete empirical interpolation\nmethod (DEIM). Our proposed algorithm is referred to as DEIM fiber sampling\n(DEIM-FS). For a rank-$r$ approximation of an $\\mathcal{O}(N^d)$ tensor,\nDEIM-FS requires access to only $dNr^{d-1}$ tensor entries, a requirement that\nscales linearly with the tensor size along each mode. We demonstrate that\nDEIM-FS achieves an approximation accuracy close to the Tucker-tensor\napproximation obtained via higher-order singular value decomposition at a\nsignificantly reduced cost. We also present DEIM-FS (iterative) that does not\nrequire access to singular vectors of the target tensor unfolding and can be\nviewed as a black-box Tucker tensor algorithm. We employ DEIM-FS to reduce the\ncomputational cost associated with solving nonlinear tensor differential\nequations (TDEs) using dynamical low-rank approximation (DLRA). The\ncomputational cost of solving DLRA equations can become prohibitive when the\nexact rank of the right-hand side tensor is large. This issue arises in many\nTDEs, especially in cases involving non-polynomial nonlinearities, where the\nright-hand side tensor has full rank. This necessitates the storage and\ncomputation of tensors of size $\\mathcal{O}(N^d)$. We show that DEIM-FS results\nin significant computational savings for DLRA by constructing a low-rank Tucker\napproximation of the right-hand side tensor on the fly. Another advantage of\nusing DEIM-FS is to significantly simplify the implementation of DLRA\nequations, irrespective of the type of TDEs. We demonstrate the efficiency of\nthe algorithm through several examples including solving high-dimensional\npartial differential equations.\n</summary>\n    <author>\n      <name>Behzad Ghahremani</name>\n    </author>\n    <author>\n      <name>Hessam Babaee</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">23 pages, 7 figures</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/2401.04249v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2401.04249v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"math.NA\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"math.NA\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.NA\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/1903.00109v3</id>\n    <updated>2019-07-04T13:44:44Z</updated>\n    <published>2019-02-28T23:50:43Z</published>\n    <title>Relative entropy for coherent states from Araki formula</title>\n    <summary>  We make a rigorous computation of the relative entropy between the vacuum\nstate and a coherent state for a free scalar in the framework of AQFT. We study\nthe case of the Rindler Wedge. Previous calculations including path integral\nmethods and computations from the lattice, give a result for such relative\nentropy which involves integrals of expectation values of the energy-momentum\nstress tensor along the considered region. However, the stress tensor is in\ngeneral non unique. That means that if we start with some stress tensor, then\nwe can \"improve\" it adding a conserved term without modifying the Poincar\\'e\ncharges. On the other hand, the presence of such improving term affects the\nnaive expectation for the relative entropy by a non vanishing boundary\ncontribution along the entangling surface. In other words, this means that\nthere is an ambiguity in the usual formula for the relative entropy coming from\nthe non uniqueness of the stress tensor. The main motivation of this work is to\nsolve this puzzle. We first show that all choices of stress tensor except the\ncanonical one are not allowed by positivity and monotonicity of the relative\nentropy. Then we fully compute the relative entropy between the vacuum and a\ncoherent state in the framework of AQFT using the Araki formula and the\ntechniques of Modular theory. After all, both results coincides and give the\nusual expression for the relative entropy calculated with the canonical stress\ntensor.\n</summary>\n    <author>\n      <name>Horacio Casini</name>\n    </author>\n    <author>\n      <name>Sergio Grillo</name>\n    </author>\n    <author>\n      <name>Diego Pontello</name>\n    </author>\n    <arxiv:doi xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10.1103/PhysRevD.99.125020</arxiv:doi>\n    <link title=\"doi\" href=\"http://dx.doi.org/10.1103/PhysRevD.99.125020\" rel=\"related\"/>\n    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Phys. Rev. D 99, 125020 (2019)</arxiv:journal_ref>\n    <link href=\"http://arxiv.org/abs/1903.00109v3\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1903.00109v3\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"hep-th\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"hep-th\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/1709.02702v1</id>\n    <updated>2017-09-08T13:41:26Z</updated>\n    <published>2017-09-08T13:41:26Z</published>\n    <title>Entropic Determinants</title>\n    <summary>  The ability of many powerful machine learning algorithms to deal with large\ndata sets without compromise is often hampered by computationally expensive\nlinear algebra tasks, of which calculating the log determinant is a canonical\nexample. In this paper we demonstrate the optimality of Maximum Entropy methods\nin approximating such calculations. We prove the equivalence between mean value\nconstraints and sample expectations in the big data limit, that Covariance\nmatrix eigenvalue distributions can be completely defined by moment information\nand that the reduction of the self entropy of a maximum entropy proposal\ndistribution, achieved by adding more moments reduces the KL divergence between\nthe proposal and true eigenvalue distribution. We empirically verify our\nresults on a variety of SparseSuite matrices and establish best practices.\n</summary>\n    <author>\n      <name>Diego Granziol</name>\n    </author>\n    <author>\n      <name>Stephen Roberts</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">9 pages, 10 figures, 2 tables</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/1709.02702v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1709.02702v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"stat.ML\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"stat.ML\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/1802.06463v3</id>\n    <updated>2020-05-06T04:09:34Z</updated>\n    <published>2018-02-18T22:49:56Z</published>\n    <title>Guaranteed Recovery of One-Hidden-Layer Neural Networks via Cross\n  Entropy</title>\n    <summary>  We study model recovery for data classification, where the training labels\nare generated from a one-hidden-layer neural network with sigmoid activations,\nalso known as a single-layer feedforward network, and the goal is to recover\nthe weights of the neural network. We consider two network models, the\nfully-connected network (FCN) and the non-overlapping convolutional neural\nnetwork (CNN). We prove that with Gaussian inputs, the empirical risk based on\ncross entropy exhibits strong convexity and smoothness {\\em uniformly} in a\nlocal neighborhood of the ground truth, as soon as the sample complexity is\nsufficiently large. This implies that if initialized in this neighborhood,\ngradient descent converges linearly to a critical point that is provably close\nto the ground truth. Furthermore, we show such an initialization can be\nobtained via the tensor method. This establishes the global convergence\nguarantee for empirical risk minimization using cross entropy via gradient\ndescent for learning one-hidden-layer neural networks, at the near-optimal\nsample and computational complexity with respect to the network input dimension\nwithout unrealistic assumptions such as requiring a fresh set of samples at\neach iteration.\n</summary>\n    <author>\n      <name>Haoyu Fu</name>\n    </author>\n    <author>\n      <name>Yuejie Chi</name>\n    </author>\n    <author>\n      <name>Yingbin Liang</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/1802.06463v3\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1802.06463v3\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"stat.ML\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"stat.ML\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/1806.01648v1</id>\n    <updated>2018-06-03T09:25:56Z</updated>\n    <published>2018-06-03T09:25:56Z</published>\n    <title>Entropy Identity inducing Non-Equilibrium Thermodynamics of Relativistic\n  Multi-Component Systems and their Newtonian Limits</title>\n    <summary>  Non-equilibrium and equilibrium thermodynamics of an interacting component in\na special-relativistic multi-component system is discussed by use of an entropy\nidentity. The special case of the corresponding free component is considered.\nEquilibrium conditions and especially the multi-component Killing relation of\nthe 4-temperature are discussed. Two axioms characterize the mixture:\nadditivity of the energy momentum tensors and of the 4-entropies of the\ncomponents generating those of the mixture. The resulting quantities of a\ncomponent and of the mixture, energy, energy flux, momentum flux, stress\ntensor, entropy, entropy flux, supply and production and their Newtonian limits\nin zeroth approximation are derived.\n</summary>\n    <author>\n      <name>Wolfgang Muschik</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">arXiv admin note: text overlap with arXiv:1701.04103</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/1806.01648v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1806.01648v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"gr-qc\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"gr-qc\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/2409.08352v1</id>\n    <updated>2024-09-12T18:30:45Z</updated>\n    <published>2024-09-12T18:30:45Z</published>\n    <title>Learning Generalized Statistical Mechanics with Matrix Product States</title>\n    <summary>  We introduce a variational algorithm based on Matrix Product States that is\ntrained by minimizing a generalized free energy defined using Tsallis entropy\ninstead of the standard Gibbs entropy. As a result, our model can generate the\nprobability distributions associated with generalized statistical mechanics.\nThe resulting model can be efficiently trained, since the resulting free energy\nand its gradient can be calculated exactly through tensor network contractions,\nas opposed to standard methods which require estimating the Gibbs entropy by\nsampling. We devise a variational annealing scheme by ramping up the inverse\ntemperature, which allows us to train the model while avoiding getting trapped\nin local minima. We show the validity of our approach in Ising spin-glass\nproblems by comparing it to exact numerical results and quasi-exact analytical\napproximations. Our work opens up new possibilities for studying generalized\nstatistical physics and solving combinatorial optimization problems with tensor\nnetworks.\n</summary>\n    <author>\n      <name>Pablo D\u00edez-Valle</name>\n    </author>\n    <author>\n      <name>Fernando Mart\u00ednez-Garc\u00eda</name>\n    </author>\n    <author>\n      <name>Juan Jos\u00e9 Garc\u00eda-Ripoll</name>\n    </author>\n    <author>\n      <name>Diego Porras</name>\n    </author>\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">6 pages, 6 figures + Supplementary material (5 pages, 5 figures)</arxiv:comment>\n    <link href=\"http://arxiv.org/abs/2409.08352v1\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2409.08352v1\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cond-mat.stat-mech\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cond-mat.stat-mech\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cond-mat.dis-nn\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"quant-ph\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n  <entry>\n    <id>http://arxiv.org/abs/1502.00326v2</id>\n    <updated>2019-01-01T19:33:09Z</updated>\n    <published>2015-02-01T23:23:41Z</published>\n    <title>Adaptive Estimation of Shannon Entropy</title>\n    <summary>  We consider estimating the Shannon entropy of a discrete distribution $P$\nfrom $n$ i.i.d. samples. Recently, Jiao, Venkat, Han, and Weissman, and Wu and\nYang constructed approximation theoretic estimators that achieve the minimax\n$L_2$ rates in estimating entropy. Their estimators are consistent given $n \\gg\n\\frac{S}{\\ln S}$ samples, where $S$ is the alphabet size, and it is the best\npossible sample complexity. In contrast, the Maximum Likelihood Estimator\n(MLE), which is the empirical entropy, requires $n\\gg S$ samples.\n  In the present paper we significantly refine the minimax results of existing\nwork. To alleviate the pessimism of minimaxity, we adopt the adaptive\nestimation framework, and show that the minimax rate-optimal estimator in Jiao,\nVenkat, Han, and Weissman achieves the minimax rates simultaneously over a\nnested sequence of subsets of distributions $P$, without knowing the alphabet\nsize $S$ or which subset $P$ lies in. In other words, their estimator is\nadaptive with respect to this nested sequence of the parameter space, which is\ncharacterized by the entropy of the distribution. We also characterize the\nmaximum risk of the MLE over this nested sequence, and show, for every subset\nin the sequence, that the performance of the minimax rate-optimal estimator\nwith $n$ samples is essentially that of the MLE with $n\\ln n$ samples, thereby\nfurther substantiating the generality of the phenomenon identified by Jiao,\nVenkat, Han, and Weissman.\n</summary>\n    <author>\n      <name>Yanjun Han</name>\n    </author>\n    <author>\n      <name>Jiantao Jiao</name>\n    </author>\n    <author>\n      <name>Tsachy Weissman</name>\n    </author>\n    <link href=\"http://arxiv.org/abs/1502.00326v2\" rel=\"alternate\" type=\"text/html\"/>\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/1502.00326v2\" rel=\"related\" type=\"application/pdf\"/>\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.IT\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"cs.IT\" scheme=\"http://arxiv.org/schemas/atom\"/>\n    <category term=\"math.IT\" scheme=\"http://arxiv.org/schemas/atom\"/>\n  </entry>\n</feed>\n"}